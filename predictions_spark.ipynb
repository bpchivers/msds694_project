{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "## setup\n",
    "conf = SparkConf().setAppName(\"final_project\")\n",
    "sc = SparkContext.getOrCreate()\n",
    "ss = SparkSession.builder.getOrCreate()\n",
    "\n",
    "def toIntegerSafe(v):\n",
    "    try:\n",
    "        return int(v)\n",
    "    except ValueError:\n",
    "        return str(v) #if it is not a float type return as a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and convert data\n",
    "filename = \"./../data/311_Cases_small.csv\"\n",
    "\n",
    "data_raw = sc.textFile(filename)\\\n",
    "             .map(lambda x: x.split(\",\"))\n",
    "\n",
    "data_raw = data_raw.map(lambda row:  [toIntegerSafe(x) for x in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Create Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schema\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"closing_time\", IntegerType(),False),\n",
    "     StructField(\"neighborhood\", StringType(),False),\n",
    "     StructField(\"category\", StringType(),False),\n",
    "     StructField(\"police_district\", StringType(),False),\n",
    "    StructField(\"responsible_agency\", StringType(), False)\n",
    "])\n",
    "\n",
    "df = ss.createDataFrame(data_raw.map(lambda x : Row(x[0],x[1],x[2],x[3],x[4])), schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Numericalize Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "def indexStringColumns(df, cols):\n",
    "    #variable newdf will be updated several times\n",
    "    newdf = df\n",
    "    \n",
    "    for c in cols:\n",
    "        #For each given colum, fits StringIndexerModel.\n",
    "        si = StringIndexer(inputCol=c, outputCol=c+\"-num\")\n",
    "        sm = si.fit(newdf)\n",
    "        #Creates a DataFame by putting the transformed values in the new colum with suffix \"-num\" \n",
    "        #and then drops the original columns.\n",
    "        #and drop the \"-num\" suffix. \n",
    "        newdf = sm.transform(newdf).drop(c)\n",
    "        newdf = newdf.withColumnRenamed(c+\"-num\", c)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnumeric = indexStringColumns(df, [\"neighborhood\", \"category\", \"police_district\", \"responsible_agency\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+--------+---------------+------------------+\n",
      "|closing_time|neighborhood|category|police_district|responsible_agency|\n",
      "+------------+------------+--------+---------------+------------------+\n",
      "|           0|        33.0|     2.0|            3.0|              14.0|\n",
      "|          23|         1.0|     0.0|            1.0|               0.0|\n",
      "|           0|         1.0|     4.0|            1.0|               0.0|\n",
      "|           0|         1.0|     1.0|            1.0|               0.0|\n",
      "|           1|        14.0|     1.0|            8.0|               0.0|\n",
      "|           0|         0.0|     0.0|            0.0|               1.0|\n",
      "|           1|         5.0|    13.0|            9.0|               2.0|\n",
      "|           0|        23.0|     0.0|            6.0|               1.0|\n",
      "|           0|        60.0|     0.0|            7.0|               1.0|\n",
      "|           0|        46.0|     0.0|            3.0|               0.0|\n",
      "|           0|        43.0|     0.0|            0.0|               1.0|\n",
      "|           6|        60.0|     1.0|            7.0|               9.0|\n",
      "|           4|         0.0|     1.0|            0.0|               0.0|\n",
      "|           0|         1.0|     1.0|            1.0|               0.0|\n",
      "|           0|         1.0|     0.0|            1.0|               1.0|\n",
      "|           0|        11.0|     0.0|            2.0|               1.0|\n",
      "|           6|         1.0|     1.0|            9.0|               0.0|\n",
      "|           0|        20.0|     0.0|            3.0|               0.0|\n",
      "|           1|        15.0|     3.0|            4.0|               3.0|\n",
      "|           0|        16.0|     0.0|            2.0|               0.0|\n",
      "+------------+------------+--------+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfnumeric.show() # very nice (in borat voice)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
